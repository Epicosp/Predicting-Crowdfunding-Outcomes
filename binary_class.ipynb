{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Find the dataset @ (CSV files 2022-04-21, https://webrobots.io/kickstarter-datasets/)\n",
    "# download link: https://s3.amazonaws.com/weruns/forfun/Kickstarter/Kickstarter_2022-04-21T03_20_08_060Z.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create master Data Frame\n",
    "before running this code, create a folder inside the repo folder called 'raw_data' containing the exctracted CSV files from the download link.\n",
    "\n",
    "The code will create a new directory called 'data' to store the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder inside the current directory to hold the processed data\n",
    "try:\n",
    "    Path('data').mkdir(parents=True, exist_ok=False)\n",
    "    print ('creating data directory')\n",
    "except:\n",
    "    print ('directory already exists')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to each file in the all_data folder\n",
    "all_paths = glob.glob('raw_data/*.csv')\n",
    "\n",
    "# list to append df's to\n",
    "list_of_df = []\n",
    "\n",
    "# loop through all paths and append each csv as a df\n",
    "for filename in all_paths:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    list_of_df.append(df)\n",
    "\n",
    "# concat all df's into one df\n",
    "master_df = pd.concat(list_of_df, axis=0, ignore_index=True)\n",
    "\n",
    "# save df as master csv\n",
    "master_df.to_csv('data/master_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpack columns containing JSON objects\n",
    "The code below takes all columns that represent dictionaries and saves them as individual csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_json(string):\n",
    "    '''\n",
    "    converts the string representation of a json object into a python dict.\n",
    "    returns np.nan if the string contains commas.\n",
    "    '''\n",
    "    try:\n",
    "        # replace single quotations to make the string represent a JSON object\n",
    "        json_acceptable_string = string.replace(\"'\", \"\\\"\")\n",
    "        return(json.loads(json_acceptable_string))\n",
    "    except:\n",
    "        # if the string is still not JSON compatible return np.nan\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(data_frame, column):\n",
    "    '''\n",
    "    unpacks dict in column to dataframe.\n",
    "    '''\n",
    "    # convert all strings into JSON objects\n",
    "    unpacked = data_frame[column].apply(make_json).to_frame()\n",
    "\n",
    "    # unpack JSON into DataFrame (future version should include 'id' column to reference whan performing merge/concat operations)\n",
    "    return pd.json_normalize(unpacked[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define which columns are represented as dicts\n",
    "unpack_list = ['category', 'creator', 'location', 'photo', 'profile', 'urls']\n",
    "\n",
    "# unpack each column of dicts, save each as their own csv\n",
    "for value in unpack_list:\n",
    "    frame = unpack(master_df, value)\n",
    "    frame.to_csv(f'data/{value}.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read category data for name and parent name\n",
    "df_category = pd.read_csv('data/category.csv')\n",
    "df_category = df_category[['name', 'parent_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns deemed unessecary\n",
    "model_data = master_df.drop(columns = ['staff_pick','converted_pledged_amount', 'spotlight', 'backers_count','usd_pledged','is_starrable','current_currency','static_usd_rate','usd_exchange_rate','usd_type','id','name', 'slug', 'category', 'creator', 'location', 'photo', 'profile', 'urls', 'country_displayable_name', 'currency_symbol', 'currency_trailing_code', 'disable_communication', 'source_url', 'currency', 'pledged', 'blurb'])\n",
    "\n",
    "# create goal_usd column so that all goal amounts are in the same units, drop fx_rate and goals afterward\n",
    "model_data['goal_usd'] = model_data['fx_rate']*model_data['goal']\n",
    "model_data = model_data.drop(columns=['fx_rate', 'goal'])\n",
    "\n",
    "# combine category data and all other date\n",
    "model_data = pd.concat([model_data, df_category], axis=1, join='inner')\n",
    "\n",
    "# create total days active column as another metric\n",
    "model_data['total_days_active'] = (model_data.deadline-model_data.launched_at)*0.00001157\n",
    "model_data['launch_time'] = (model_data.launched_at-model_data.created_at)*0.00001157\n",
    "model_data = model_data.drop(columns=['state_changed_at', 'deadline', 'launched_at'])\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows that have state 'live' or 'cancelled'\n",
    "live_projects = model_data[model_data['state'] == 'live']\n",
    "model_data = model_data.drop(model_data[model_data['state'] == 'live'].index, axis=0)\n",
    "model_data = model_data.drop(model_data[model_data['state'] == 'canceled'].index, axis=0)\n",
    "model_data = model_data.reset_index(drop=True)\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding of non neumerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init encoder for x values\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# new encoder for y variable (to make sure that we can reverse encoding)\n",
    "y_encoder = LabelEncoder()\n",
    "model_data['state'] = y_encoder.fit_transform(model_data['state'])\n",
    "\n",
    "# encode boolean and string type columns\n",
    "encoding_columns = (model_data.select_dtypes(include=['bool', 'object'])).columns\n",
    "for column in encoding_columns:\n",
    "    model_data[column] = encoder.fit_transform(model_data[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Validation and training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'created at' to datetime format\n",
    "model_data['Date Created'] = pd.to_datetime(model_data['created_at'], unit='s')\n",
    "model_data['Date Created'] = model_data['Date Created'].dt.strftime('%Y/%m/%d')\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA's\n",
    "model_data = model_data.dropna()\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset\n",
    "val_start_date = '2021/02/01'\n",
    "val_end_date = '2021/08/07'\n",
    "val_mask = (model_data['Date Created'] >= val_start_date) & (model_data['Date Created'] <= val_end_date)\n",
    "val_dataset = model_data[val_mask]\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test dataset\n",
    "train_test_dataset = model_data.loc[val_mask == False]\n",
    "train_test_dataset = train_test_dataset.drop(['Date Created', 'created_at'], axis=1)\n",
    "train_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test splits for Test and Validation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and y variables\n",
    "X = train_test_dataset.drop(columns=['state'])\n",
    "y = train_test_dataset.state\n",
    "\n",
    "# generate 70% train/test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
    "                                                       random_state = 1,\n",
    "                                                       stratify = y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split validation dataset into X and y variables\n",
    "X_val = val_dataset.drop(columns=['state', 'Date Created', 'created_at'])\n",
    "y_val = val_dataset.state\n",
    "\n",
    "# generate 70% train/validation split \n",
    "X_train_val, X_test_val, y_train_val, y_test_val = train_test_split(X_val, y_val, test_size=0.3,\n",
    "                                                     random_state = 1,\n",
    "                                                     stratify = y_val)\n",
    "X_train_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale values using standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale Train and testing set, columns=X.columns to keep column headers.\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
    "X_val_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_val), columns=X_val.columns)\n",
    "X_val_test_scaled = pd.DataFrame(scaler.transform(X_test_val), columns=X_val.columns)\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init and fit RF classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# init new RF calssifier for validation set\n",
    "rf_validation_classifier = RandomForestClassifier()\n",
    "rf_validation_classifier.fit(X_val_train_scaled, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform predictions on testing and validation data\n",
    "predictions  = rf_classifier.predict(X_test_scaled)\n",
    "validation_predictions = rf_validation_classifier.predict(X_val_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode values using inverse transform\n",
    "predictions_decoded = y_encoder.inverse_transform(predictions)\n",
    "y_test_decoded = y_encoder.inverse_transform(y_test)\n",
    "validation_predictions_decoded = y_encoder.inverse_transform(validation_predictions)\n",
    "y_val_decoded = y_encoder.inverse_transform(y_test_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view model importance of features for the model\n",
    "importances = pd.DataFrame(zip(X.columns, rf_classifier.feature_importances_), columns = ['Feature','Importance value']).set_index('Feature')\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification reports for the test and validation set\n",
    "test_report = classification_report(y_test_decoded, predictions_decoded)\n",
    "val_report = classification_report(y_val_decoded, validation_predictions_decoded)\n",
    "report_string = f'Random Forest test report\\n-----------------------------------------------------\\n{test_report}\\nRandom Forest validation report\\n-----------------------------------------------------\\n{val_report}'\n",
    "print(report_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view confusion matrix (0=failed, 1=success)\n",
    "cm = pd.DataFrame(confusion_matrix(y_test_decoded, predictions_decoded), index=['Cancelled','Failed', 'live', 'Successful'], columns=['Cancelled','Failed', 'live', 'Successful'])\n",
    "val_cm = pd.DataFrame(confusion_matrix(y_val_decoded, validation_predictions_decoded), index=['Cancelled','Failed', 'live', 'Successful'], columns=['Cancelled','Failed', 'live', 'Successful'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ROC curve and AUC for the testing set\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, predictions)\n",
    "auc_test = round(auc(fpr_test, tpr_test), 3)\n",
    "\n",
    "# Calculate the ROC curve and AUC for the validation set\n",
    "fpr_val, tpr_val, thresholds_val = roc_curve(y_val, validation_predictions)\n",
    "auc_val = round(auc(fpr_val, tpr_val), 3)\n",
    "\n",
    "# Create a DataFrame with the fpr and tpr results\n",
    "roc_df_test = pd.DataFrame({\"FPR Test\": fpr_test, \"TPR Test\": tpr_test})\n",
    "roc_df_val = pd.DataFrame({\"FPR Val\": fpr_val, \"TPR Val\": tpr_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test set ROC curve\n",
    "roc_df_test.plot(figsize = (10,6), x=\"FPR Test\", y=\"TPR Test\", title=f\"Test ROC Curve (AUC={auc_test})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot val set ROC curve\n",
    "roc_df_val.plot(figsize=(10,6), x=\"FPR Val\", y=\"TPR Val\", title=f\"Validation ROC Curve (AUC={auc_val})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(kernel='linear', max_iter=50)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the accuracy\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_val, y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the test data\n",
    "predictions = classifier.predict(X_val)\n",
    "results = pd.DataFrame({\n",
    "    \"Prediction\": predictions, \n",
    "    \"Actual\": y_val\n",
    "}).reset_index(drop=True)\n",
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_val, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "cm, index=['Actual 0', 'Actual 1', 'Actual 2', 'Actual 3'], columns=['Predicted 0', 'Predicted 1', 'Predicted 2', 'Predicted 3']\n",
    ")\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification report\n",
    "print(classification_report(y_val, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# SKLearn Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init and fit Neural Networks classifier\n",
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "nn_clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                       hidden_layer_sizes=(4, 2), random_state=1)\n",
    "\n",
    "nn_clf.fit(X, y)\n",
    "#MLPClassifier(alpha=1e-05, hidden_layer_sizes=(6, 2), random_state=1,\n",
    "              #solver='lbfgs')\n",
    "#nn_clf.fit(X_train_scaled, y_train.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data\n",
    "nn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {nn_clf.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {nn_clf.score(X_val, y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the test data\n",
    "predictions = nn_clf.predict(X_val)\n",
    "results = pd.DataFrame({\n",
    "    \"Prediction\": predictions, \n",
    "    \"Actual\": y_val\n",
    "}).reset_index(drop=True)\n",
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_val, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "cm, index=['Actual 0', 'Actual 1', 'Actual 2', 'Actual 3'], columns=['Predicted 0', 'Predicted 1', 'Predicted 2', 'Predicted 3']\n",
    ")\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    " # XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init datasets as XGB matrices\n",
    "xgb_train = xgb.DMatrix(np.array(X_train_resampled), label=np.array(y_train_resampled.bins))\n",
    "xgb_test = xgb.DMatrix(np.array(X_test_scaled), label=np.array(y_test.bins))\n",
    "\n",
    "# specify parameters via map\n",
    "param = {\n",
    "    'max_depth':5, \n",
    "    'eta':1, \n",
    "    'num_class':8, \n",
    "    'gamma':0,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':10,\n",
    "    'num_parallel_tree':1\n",
    "    }\n",
    "num_round = 5\n",
    "\n",
    "# fit XGB classifier\n",
    "bst = xgb.train(param, xgb_train, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "predictions = bst.predict(xgb_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "097c1c50147d69c70dea14784d774fa19f0c571c55d8af2791c45a24b5968fed"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
